{
  "train_batch_size": "auto",
  "train_micro_batch_size_per_gpu": "auto",
  "gradient_accumulation_steps": "auto",
  "gradient_clipping": 1.0,
  "steps_per_print": 10,
  "wall_clock_breakdown": false,
  
  "_comment_precision": "Precision will be automatically configured based on GPU capabilities",
  
  "zero_optimization": {
    "stage": 2,
    "allgather_partitions": true,
    "allgather_bucket_size": 2e8,
    "overlap_comm": true,
    "reduce_scatter": true,
    "reduce_bucket_size": 2e8,
    "contiguous_gradients": true,
    "cpu_offload": false,
    "_comment_cpu_offload": "Set to true if you encounter OOM errors"
  },
  
  "optimizer": {
    "type": "AdamW",
    "params": {
      "lr": "auto",
      "betas": "auto",
      "eps": "auto",
      "weight_decay": "auto"
    }
  },
  
  "scheduler": {
    "type": "WarmupLR",
    "params": {
      "warmup_min_lr": "auto",
      "warmup_max_lr": "auto",
      "warmup_num_steps": "auto"
    }
  },
  
  "activation_checkpointing": {
    "partition_activations": false,
    "cpu_checkpointing": false,
    "contiguous_memory_optimization": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
  },
  
  "comms_logger": {
    "enabled": false
  },
  
  "tensorboard": {
    "enabled": true,
    "output_path": "./logs/tensorboard/",
    "job_name": "codellama_finetune"
  },
  
  "flops_profiler": {
    "enabled": false,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
  },
  
  "_memory_optimization_notes": {
    "for_low_memory": "Set zero_optimization.cpu_offload to true",
    "for_very_low_memory": "Use zero_optimization.stage 3 instead of 2",
    "batch_size_tuning": "Reduce train_micro_batch_size_per_gpu if OOM occurs"
  }
}
